{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "import colorsys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from nettools.monoplex import NetworkGenerator \n",
    "from nettools.multiplex import MultiplexConstructor\n",
    "from nettools.multiplex import InterMeasures\n",
    "from nettools.monoplex import CentralityMeasure\n",
    "from nettools.epidemic import SISMultiplex, SIRMultiplex\n",
    "from nettools.utils import load_multinet_by_name, NX_CENTRALITY\n",
    "from nettools.utils.ctest import spread_eff_centr_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centrality for multiplex synthetic networks\n",
    "In this notebook I describe centrality measure for *monoplex* and *multiplex* synthetic networks, besides that I will spread disease on each tested network, using seed nodes with greatest centrality score, results will be noted and ploted. My aim is to find best seed node for multiplex networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reasearch approach\n",
    "In my reaserch I will test centrality on:\n",
    "* Aggregated networks\n",
    "* Weighted Aggregated networks\n",
    "* Mulitplex Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic networks used in reaserch\n",
    "In my work I will use five synthetic networks: \n",
    "* **ER-ER** Network\n",
    "* **ER-BA** Network\n",
    "* **BA-BB** Network\n",
    "* **BA-BA** Not correlated Network\n",
    "* **BA-BA** Correlated Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reaserch enviroment\n",
    "<img src=\"../images/settings_logo.jpg\", width=400, height=400></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_deg = 6.0\n",
    "network_size = 300\n",
    "ng = NetworkGenerator(network_size)\n",
    "network_ba_1 = ng.ba_network(m0=int(avg_deg / 2))\n",
    "network_ba_2 = ng.ba_network(m0=int(avg_deg / 2))\n",
    "network_er_1 = ng.er_network(p=(avg_deg / float(network_size)))\n",
    "network_er_2 = ng.er_network(p=(avg_deg / float(network_size)))\n",
    "network_bb_1 = ng.bb_network(m0=int(avg_deg / 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define network constructor and create correlated network for **BA** Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mc = MultiplexConstructor()\n",
    "network_corr_ba_1 = mc.rewire_hubs(network_ba_1, rsteps=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create multiplex networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi_erer = mc.construct(network_er_1, network_er_2)\n",
    "multi_erba = mc.construct(network_er_2, network_ba_1)\n",
    "multi_babb = mc.construct(network_ba_1, network_bb_1)\n",
    "multi_baba_nc = mc.construct(network_ba_2, network_ba_1)\n",
    "multi_baba_corr = mc.construct(network_ba_1, network_corr_ba_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preparing 5 networks for test, create 2 single layer networks for veryfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network_ba_single = ng.ba_network(m0=int(avg_deg / 2))\n",
    "network_er_single = ng.er_network(p=(avg_deg / float(network_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiplex Networks\n",
    "<img src=\"../images/multi.png\", width=400, height=400></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Centrality for aggregated network\n",
    "In second step network centrality will be examined using aggregated networks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agg_net_erer = InterMeasures.aggregate(multi_erer.network)\n",
    "agg_net_erba = InterMeasures.aggregate(multi_erba.network)\n",
    "agg_net_babb = InterMeasures.aggregate(multi_babb.network)\n",
    "agg_net_baba_nc = InterMeasures.aggregate(multi_baba_nc.network)\n",
    "agg_net_baba_corr = InterMeasures.aggregate(multi_baba_corr.network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Experiment:\n",
    "During test I found that centrality score and spreading efficiency correlation hardly depends on epidemic rate used on each layer. In first experiment I will use same epidemic rate, in second step I will use different epidemic rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Experiment:\n",
    "In second experiment I will set different spreading rates for each layer.\n",
    "<br>\n",
    "$$ \\beta_A = 0.1 $$ <br> $$ \\beta_{AB} = 0.1 $$ <br> $$ \\beta_B = 0.6 $$ <br> $$\\beta_{AB} = 0.6$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 ER-ER Network\n",
    "Centrality score for each node is computed, in next step this score will be used to begin epidemy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "for idx, method in enumerate(NX_CENTRALITY.keys()):\n",
    "    if method == \"supernode\":\n",
    "        continue\n",
    "    avg_results = np.zeros((500, 50))\n",
    "    for n_time in range(0, 500):\n",
    "        cn = CentralityMeasure(agg_net_erer)\n",
    "        results_cn = cn.network_cn(method)\n",
    "        if method == 'hits':\n",
    "            results_cn = results_cn[1]\n",
    "        best_nodes = sorted(results_cn.items(), key=lambda x: x[1])[::-1]\n",
    "        beta_param = {0: {0: 0.1, 1: 0.1}, 1: {0: 0.6, 1: 0.6}}\n",
    "        rec_param = {0: {0: 1.0, 1: 1.0}, 1: {0: 1.0, 1: 1.0}}\n",
    "        sir = SIRMultiplex(multi_erer, beta=beta_param, mu=rec_param, seed_nodes=[best_nodes[0][0]])\n",
    "        result_sir = sir.run(epochs=50)\n",
    "        avg_results[n_time] = np.array(result_sir)\n",
    "    plt.plot(np.mean(avg_results, axis=0) / float(network_size * multi_erer.network.shape[2]), \n",
    "             hold=True, label=method)\n",
    "plt.legend()\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cent_dict_erer = {}\n",
    "cent_val_erer = {}\n",
    "cent_dict_erer_15 = {}\n",
    "cm_erer = CentralityMeasure(agg_net_erer)\n",
    "for method in NX_CENTRALITY.keys():\n",
    "    if method == 'supernode':\n",
    "        continue\n",
    "    results = cm_erer.network_cn(method)\n",
    "    if method == 'hits':\n",
    "        results = results[1]\n",
    "    best_nodes = sorted(results.items(), key=lambda x: x[1])[::-1]\n",
    "    cent_val_erer[method] = sorted(results.values())[::-1]\n",
    "    cent_dict_erer[method] = [cnt[0] for cnt in best_nodes]\n",
    "    cent_dict_erer_15[method] = [cnt[0] for cnt in best_nodes[:15]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "scores_15 = {}\n",
    "mean_realisation = 50\n",
    "for method, nodes in cent_dict_erer.items():\n",
    "    node_labels = []\n",
    "    nodes_scores = []\n",
    "    for node in nodes:\n",
    "        mean_spread = []\n",
    "        for _ in range(mean_realisation):\n",
    "            beta_param = {0: {0: 0.1, 1: 0.1}, 1: {0: 0.6, 1: 0.6}}\n",
    "            rec_param = {0: {0: 1.0, 1: 1.0}, 1: {0: 1.0, 1: 1.0}}\n",
    "            sis = SIRMultiplex(multi_erer, beta=beta_param, mu=rec_param, seed_nodes=[node])\n",
    "            sis.run(epochs=10, visualize=False)\n",
    "            mean_spread.append(sis.get_num('i') + sis.get_num('r'))\n",
    "        node_labels.append(node)\n",
    "        nodes_scores.append(np.mean(mean_spread))\n",
    "    scores[method] = node_labels, nodes_scores\n",
    "    scores_15[method] = nodes_scores[:15]\n",
    "pd.DataFrame.from_dict(scores_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_mean(x, nnodes):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0))\n",
    "    return (cumsum[nnodes:] - cumsum[:-nnodes]) / nnodes\n",
    "\n",
    "idx_counter = 1\n",
    "colors = \"bgrcmrkygbb\"\n",
    "fig=plt.figure(figsize=(20, 20), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.subplots_adjust(top=1.5)\n",
    "for method, nd_lab_scores in scores.items():\n",
    "    sp = plt.subplot(840 + idx_counter)\n",
    "    sp.plot(running_mean(nd_lab_scores[1], 30), colors[idx_counter + 1])\n",
    "    sp.set_title(method)\n",
    "    idx_counter += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_mean(x, nnodes):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0))\n",
    "    return (cumsum[nnodes:] - cumsum[:-nnodes]) / nnodes\n",
    "\n",
    "idx_counter = 1\n",
    "corr_kendal = {}\n",
    "colors = \"bgrcmrkygbcmgrc\"\n",
    "fig=plt.figure(figsize=(20, 20), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.subplots_adjust(top=1.5)\n",
    "for method, nd_lab_scores in scores.items():\n",
    "    normalized_spread = (np.array(nd_lab_scores[1]) - np.mean(nd_lab_scores[1])) / np.std(nd_lab_scores[1])\n",
    "    normalized_cent = (cent_val_erer[method] - np.mean(cent_val_erer[method])) / np.std(cent_val_erer[method])\n",
    "    sp = plt.subplot(840 + idx_counter)\n",
    "    sp.plot(normalized_spread, colors[idx_counter], label=\"spreading eff\")\n",
    "    sp.plot(running_mean(normalized_spread, 30), colors[idx_counter + 1], label=\"spreading mean\")\n",
    "    sp.plot(normalized_cent, colors[idx_counter + 2], label=\"centrality\")\n",
    "    sp.legend()\n",
    "    tau, p_value = stats.kendalltau(\n",
    "                    nd_lab_scores[1],\n",
    "                    cent_val_erer[method]\n",
    "                )\n",
    "    corr_kendal[method] = [tau]\n",
    "    sp.set_title(method)\n",
    "    idx_counter += 1\n",
    "plt.show()\n",
    "print(\"Kendal Correlation\")\n",
    "pd.DataFrame.from_dict(corr_kendal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "print(\"Network generated and constructed!\")\n",
    "beta_param = {0: {0: 0.1, 1: 0.1}, 1: {0: 0.6, 1: 0.6}}\n",
    "rec_param = {0: {0: 1.0, 1: 1.0}, 1: {0: 1.0, 1: 1.0}}\n",
    "test_props = {'mean_num': 1500, \"epochs\": 35, \"beta\": beta_param, \"mu\": rec_param}\n",
    "print(\"Start process...\")\n",
    "spread_val, cent_scores, results_names = spread_eff_centr_test(multi_erer, test_properties=test_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 20), dpi=80, facecolor='w', edgecolor='k')\n",
    "for method_idx in range(1, spread_val.shape[0]):\n",
    "    method_scores_spread = spread_val[method_idx]\n",
    "    method_scores_cent = cent_scores[method_idx]\n",
    "    method_scores_cent = method_scores_cent - np.min(method_scores_cent)\n",
    "    method_scores_cent = 0.65 * (method_scores_cent / np.max(method_scores_cent))\n",
    "    # Find data ranks\n",
    "    temp_sort = np.argsort(method_scores_cent)\n",
    "    data_centrality_rank = np.empty(len(method_scores_cent), int)\n",
    "    data_centrality_rank[temp_sort] = np.arange(len(method_scores_cent))\n",
    "    sp = plt.subplot(240 + method_idx)\n",
    "    for node_id in range(network_size):\n",
    "        color_rgb = colorsys.hsv_to_rgb(0.65 - method_scores_cent[node_id], 0.5, 1.0)\n",
    "        sp.scatter(data_centrality_rank[node_id], method_scores_spread[node_id],\n",
    "                   c=(color_rgb[0], color_rgb[1], color_rgb[2], 1))\n",
    "    sp.set_title(results_names[method_idx - 1])\n",
    "    sp.set_ylim([np.min(method_scores_spread), np.max(method_scores_spread)])\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 BA-BA Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "for idx, method in enumerate(NX_CENTRALITY.keys()):\n",
    "    if method == \"supernode\":\n",
    "        continue\n",
    "    avg_results = np.zeros((500, 50))\n",
    "    for n_time in range(0, 500):\n",
    "        cn = CentralityMeasure(agg_net_baba_nc)\n",
    "        results_cn = cn.network_cn(method)\n",
    "        if method == 'hits':\n",
    "            results_cn = results_cn[1]\n",
    "        best_nodes = sorted(results_cn.items(), key=lambda x: x[1])[::-1]\n",
    "        beta_param = {0: {0: 0.1, 1: 0.1}, 1: {0: 0.6, 1: 0.6}}\n",
    "        rec_param = {0: {0: 1.0, 1: 1.0}, 1: {0: 1.0, 1: 1.0}}\n",
    "        sir = SIRMultiplex(multi_baba_nc, beta=beta_param, mu=rec_param, seed_nodes=[best_nodes[0][0]])\n",
    "        result_sir = sir.run(epochs=50)\n",
    "        avg_results[n_time] = np.array(result_sir)\n",
    "    plt.plot(np.mean(avg_results, axis=0) / float(network_size * multi_baba_nc.network.shape[2]), \n",
    "             hold=True, label=method)\n",
    "plt.legend()\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cent_dict_baba = {}\n",
    "cent_val_baba = {}\n",
    "cent_dict_baba_15 = {}\n",
    "cm_baba = CentralityMeasure(agg_net_baba_nc)\n",
    "for method in NX_CENTRALITY.keys():\n",
    "    if method == 'supernode':\n",
    "        continue\n",
    "    results = cm_baba.network_cn(method)\n",
    "    if method == 'hits':\n",
    "        results = results[1]\n",
    "    best_nodes = sorted(results.items(), key=lambda x: x[1])[::-1]\n",
    "    cent_val_baba[method] = sorted(results.values())[::-1]\n",
    "    cent_dict_baba[method] = [cnt[0] for cnt in best_nodes]\n",
    "    cent_dict_baba_15[method] = [cnt[0] for cnt in best_nodes[:15]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "scores_15 = {}\n",
    "mean_realisation = 50\n",
    "for method, nodes in cent_dict_baba.items():\n",
    "    node_labels = []\n",
    "    nodes_scores = []\n",
    "    for node in nodes:\n",
    "        mean_spread = []\n",
    "        for _ in range(mean_realisation):\n",
    "            beta_param = {0: {0: 0.1, 1: 0.1}, 1: {0: 0.6, 1: 0.6}}\n",
    "            rec_param = {0: {0: 1.0, 1: 1.0}, 1: {0: 1.0, 1: 1.0}}\n",
    "            sis = SIRMultiplex(multi_baba_nc, beta=beta_param, mu=rec_param, seed_nodes=[node])\n",
    "            sis.run(epochs=10, visualize=False)\n",
    "            mean_spread.append(sis.get_num('i') + sis.get_num('r'))\n",
    "        node_labels.append(node)\n",
    "        nodes_scores.append(np.mean(mean_spread))\n",
    "    scores[method] = node_labels, nodes_scores\n",
    "    scores_15[method] = nodes_scores[:15]\n",
    "pd.DataFrame.from_dict(scores_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_mean(x, nnodes):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0))\n",
    "    return (cumsum[nnodes:] - cumsum[:-nnodes]) / nnodes\n",
    "\n",
    "idx_counter = 1\n",
    "colors = \"bgrcmrkygbb\"\n",
    "fig=plt.figure(figsize=(20, 20), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.subplots_adjust(top=1.5)\n",
    "for method, nd_lab_scores in scores.items():\n",
    "    sp = plt.subplot(840 + idx_counter)\n",
    "    sp.plot(running_mean(nd_lab_scores[1], 30), colors[idx_counter + 1])\n",
    "    sp.set_title(method)\n",
    "    idx_counter += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_mean(x, nnodes):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0))\n",
    "    return (cumsum[nnodes:] - cumsum[:-nnodes]) / nnodes\n",
    "\n",
    "idx_counter = 1\n",
    "corr_kendal = {}\n",
    "colors = \"bgrcmrkygbcmgrc\"\n",
    "fig=plt.figure(figsize=(20, 20), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.subplots_adjust(top=1.5)\n",
    "for method, nd_lab_scores in scores.items():\n",
    "    normalized_spread = (np.array(nd_lab_scores[1]) - np.mean(nd_lab_scores[1])) / np.std(nd_lab_scores[1])\n",
    "    normalized_cent = (cent_val_baba[method] - np.mean(cent_val_baba[method])) / np.std(cent_val_baba[method])\n",
    "    sp = plt.subplot(840 + idx_counter)\n",
    "    sp.plot(normalized_spread, colors[idx_counter], label=\"spreading eff\")\n",
    "    sp.plot(running_mean(normalized_spread, 30), colors[idx_counter + 1], label=\"spreading mean\")\n",
    "    sp.plot(normalized_cent, colors[idx_counter + 2], label=\"centrality\")\n",
    "    sp.legend()\n",
    "    tau, p_value = stats.kendalltau(\n",
    "                    nd_lab_scores[1],\n",
    "                    cent_val_baba[method]\n",
    "                )\n",
    "    corr_kendal[method] = [tau]\n",
    "    sp.set_title(method)\n",
    "    idx_counter += 1\n",
    "plt.show()\n",
    "print(\"Kendal Correlation\")\n",
    "pd.DataFrame.from_dict(corr_kendal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "print(\"Network generated and constructed!\")\n",
    "beta_param = {0: {0: 0.1, 1: 0.1}, 1: {0: 0.6, 1: 0.6}}\n",
    "rec_param = {0: {0: 1.0, 1: 1.0}, 1: {0: 1.0, 1: 1.0}}\n",
    "test_props = {'mean_num': 1500, \"epochs\": 35, \"beta\": beta_param, \"mu\": rec_param}\n",
    "print(\"Start process...\")\n",
    "spread_val, cent_scores, results_names = spread_eff_centr_test(multi_baba_nc, test_properties=test_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 20), dpi=80, facecolor='w', edgecolor='k')\n",
    "for method_idx in range(1, spread_val.shape[0]):\n",
    "    method_scores_spread = spread_val[method_idx]\n",
    "    method_scores_cent = cent_scores[method_idx]\n",
    "    method_scores_cent = method_scores_cent - np.min(method_scores_cent)\n",
    "    method_scores_cent = 0.65 * (method_scores_cent / np.max(method_scores_cent))\n",
    "    # Find data ranks\n",
    "    temp_sort = np.argsort(method_scores_cent)\n",
    "    data_centrality_rank = np.empty(len(method_scores_cent), int)\n",
    "    data_centrality_rank[temp_sort] = np.arange(len(method_scores_cent))\n",
    "    sp = plt.subplot(240 + method_idx)\n",
    "    for node_id in range(network_size):\n",
    "        color_rgb = colorsys.hsv_to_rgb(0.65 - method_scores_cent[node_id], 0.5, 1.0)\n",
    "        sp.scatter(data_centrality_rank[node_id], method_scores_spread[node_id],\n",
    "                   c=(color_rgb[0], color_rgb[1], color_rgb[2], 1))\n",
    "    sp.set_title(results_names[method_idx - 1])\n",
    "    sp.set_ylim([np.min(method_scores_spread), np.max(method_scores_spread)])\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 ER-BA Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "for idx, method in enumerate(NX_CENTRALITY.keys()):\n",
    "    if method == \"supernode\":\n",
    "        continue\n",
    "    avg_results = np.zeros((500, 50))\n",
    "    for n_time in range(0, 500):\n",
    "        cn = CentralityMeasure(agg_net_erba)\n",
    "        results_cn = cn.network_cn(method)\n",
    "        if method == 'hits':\n",
    "            results_cn = results_cn[1]\n",
    "        best_nodes = sorted(results_cn.items(), key=lambda x: x[1])[::-1]\n",
    "        beta_param = {0: {0: 0.1, 1: 0.1}, 1: {0: 0.6, 1: 0.6}}\n",
    "        rec_param = {0: {0: 1.0, 1: 1.0}, 1: {0: 1.0, 1: 1.0}}\n",
    "        sir = SIRMultiplex(multi_erba, beta=beta_param, mu=rec_param, seed_nodes=[best_nodes[0][0]])\n",
    "        result_sir = sir.run(epochs=50)\n",
    "        avg_results[n_time] = np.array(result_sir)\n",
    "    plt.plot(np.mean(avg_results, axis=0) / float(network_size * multi_erba.network.shape[2]), \n",
    "             hold=True, label=method)\n",
    "plt.legend()\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cent_dict_erba = {}\n",
    "cent_val_erba = {}\n",
    "cent_dict_erba_15 = {}\n",
    "cm_erba = CentralityMeasure(agg_net_erba)\n",
    "for method in NX_CENTRALITY.keys():\n",
    "    if method == 'supernode':\n",
    "        continue\n",
    "    results = cm_erba.network_cn(method)\n",
    "    if method == 'hits':\n",
    "        results = results[1]\n",
    "    best_nodes = sorted(results.items(), key=lambda x: x[1])[::-1]\n",
    "    cent_val_erba[method] = sorted(results.values())[::-1]\n",
    "    cent_dict_erba[method] = [cnt[0] for cnt in best_nodes]\n",
    "    cent_dict_erba_15[method] = [cnt[0] for cnt in best_nodes[:15]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "scores_15 = {}\n",
    "mean_realisation = 50\n",
    "for method, nodes in cent_dict_erba.items():\n",
    "    node_labels = []\n",
    "    nodes_scores = []\n",
    "    for node in nodes:\n",
    "        mean_spread = []\n",
    "        for _ in range(mean_realisation):\n",
    "            beta_param = {0: {0: 0.1, 1: 0.1}, 1: {0: 0.6, 1: 0.6}}\n",
    "            rec_param = {0: {0: 1.0, 1: 1.0}, 1: {0: 1.0, 1: 1.0}}\n",
    "            sis = SIRMultiplex(multi_erba, beta=beta_param, mu=rec_param, seed_nodes=[node])\n",
    "            sis.run(epochs=10, visualize=False)\n",
    "            mean_spread.append(sis.get_num('i') + sis.get_num('r'))\n",
    "        node_labels.append(node)\n",
    "        nodes_scores.append(np.mean(mean_spread))\n",
    "    scores[method] = node_labels, nodes_scores\n",
    "    scores_15[method] = nodes_scores[:15]\n",
    "pd.DataFrame.from_dict(scores_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_mean(x, nnodes):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0))\n",
    "    return (cumsum[nnodes:] - cumsum[:-nnodes]) / nnodes\n",
    "\n",
    "idx_counter = 1\n",
    "colors = \"bgrcmrkygbb\"\n",
    "fig=plt.figure(figsize=(20, 20), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.subplots_adjust(top=1.5)\n",
    "for method, nd_lab_scores in scores.items():\n",
    "    sp = plt.subplot(840 + idx_counter)\n",
    "    sp.plot(running_mean(nd_lab_scores[1], 30), colors[idx_counter + 1])\n",
    "    sp.set_title(method)\n",
    "    idx_counter += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_mean(x, nnodes):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0))\n",
    "    return (cumsum[nnodes:] - cumsum[:-nnodes]) / nnodes\n",
    "\n",
    "idx_counter = 1\n",
    "corr_kendal = {}\n",
    "colors = \"bgrcmrkygbcmgrc\"\n",
    "fig=plt.figure(figsize=(20, 20), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.subplots_adjust(top=1.5)\n",
    "for method, nd_lab_scores in scores.items():\n",
    "    normalized_spread = (np.array(nd_lab_scores[1]) - np.mean(nd_lab_scores[1])) / np.std(nd_lab_scores[1])\n",
    "    normalized_cent = (cent_val_erba[method] - np.mean(cent_val_erba[method])) / np.std(cent_val_erba[method])\n",
    "    sp = plt.subplot(840 + idx_counter)\n",
    "    sp.plot(normalized_spread, colors[idx_counter], label=\"spreading eff\")\n",
    "    sp.plot(running_mean(normalized_spread, 30), colors[idx_counter + 1], label=\"spreading mean\")\n",
    "    sp.plot(normalized_cent, colors[idx_counter + 2], label=\"centrality\")\n",
    "    sp.legend()\n",
    "    tau, p_value = stats.kendalltau(\n",
    "                    nd_lab_scores[1],\n",
    "                    cent_val_erba[method]\n",
    "                )\n",
    "    corr_kendal[method] = [tau]\n",
    "    sp.set_title(method)\n",
    "    idx_counter += 1\n",
    "plt.show()\n",
    "print(\"Kendal Correlation\")\n",
    "pd.DataFrame.from_dict(corr_kendal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "print(\"Network generated and constructed!\")\n",
    "beta_param = {0: {0: 0.1, 1: 0.1}, 1: {0: 0.6, 1: 0.6}}\n",
    "rec_param = {0: {0: 1.0, 1: 1.0}, 1: {0: 1.0, 1: 1.0}}\n",
    "test_props = {'mean_num': 1500, \"epochs\": 35, \"beta\": beta_param, \"mu\": rec_param}\n",
    "print(\"Start process...\")\n",
    "spread_val, cent_scores, results_names = spread_eff_centr_test(multi_baba_nc, test_properties=test_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 20), dpi=80, facecolor='w', edgecolor='k')\n",
    "for method_idx in range(1, spread_val.shape[0]):\n",
    "    method_scores_spread = spread_val[method_idx]\n",
    "    method_scores_cent = cent_scores[method_idx]\n",
    "    method_scores_cent = method_scores_cent - np.min(method_scores_cent)\n",
    "    method_scores_cent = 0.65 * (method_scores_cent / np.max(method_scores_cent))\n",
    "    # Find data ranks\n",
    "    temp_sort = np.argsort(method_scores_cent)\n",
    "    data_centrality_rank = np.empty(len(method_scores_cent), int)\n",
    "    data_centrality_rank[temp_sort] = np.arange(len(method_scores_cent))\n",
    "    sp = plt.subplot(240 + method_idx)\n",
    "    for node_id in range(network_size):\n",
    "        color_rgb = colorsys.hsv_to_rgb(0.65 - method_scores_cent[node_id], 0.5, 1.0)\n",
    "        sp.scatter(data_centrality_rank[node_id], method_scores_spread[node_id],\n",
    "                   c=(color_rgb[0], color_rgb[1], color_rgb[2], 1))\n",
    "    sp.set_title(results_names[method_idx - 1])\n",
    "    sp.set_ylim([np.min(method_scores_spread), np.max(method_scores_spread)])\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 BA - BA Network Correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "for idx, method in enumerate(NX_CENTRALITY.keys()):\n",
    "    if method == \"supernode\":\n",
    "        continue\n",
    "    avg_results = np.zeros((500, 50))\n",
    "    for n_time in range(0, 500):\n",
    "        cn = CentralityMeasure(agg_net_baba_corr)\n",
    "        results_cn = cn.network_cn(method)\n",
    "        if method == 'hits':\n",
    "            results_cn = results_cn[1]\n",
    "        best_nodes = sorted(results_cn.items(), key=lambda x: x[1])[::-1]\n",
    "        beta_param = {0: {0: 0.1, 1: 0.1}, 1: {0: 0.6, 1: 0.6}}\n",
    "        rec_param = {0: {0: 1.0, 1: 1.0}, 1: {0: 1.0, 1: 1.0}}\n",
    "        sir = SIRMultiplex(multi_baba_corr, beta=beta_param, mu=rec_param, seed_nodes=[best_nodes[0][0]])\n",
    "        result_sir = sir.run(epochs=50)\n",
    "        avg_results[n_time] = np.array(result_sir)\n",
    "    plt.plot(np.mean(avg_results, axis=0) / float(network_size * multi_baba_corr.network.shape[2]), \n",
    "             hold=True, label=method)\n",
    "plt.legend()\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cent_dict_baba_corr = {}\n",
    "cent_val_baba_corr = {}\n",
    "cent_dict_baba_corr_15 = {}\n",
    "cm_baba_corr = CentralityMeasure(agg_net_baba_corr)\n",
    "for method in NX_CENTRALITY.keys():\n",
    "    if method == 'supernode':\n",
    "        continue\n",
    "    results = cm_baba_corr.network_cn(method)\n",
    "    if method == 'hits':\n",
    "        results = results[1]\n",
    "    best_nodes = sorted(results.items(), key=lambda x: x[1])[::-1]\n",
    "    cent_val_baba_corr[method] = sorted(results.values())[::-1]\n",
    "    cent_dict_baba_corr[method] = [cnt[0] for cnt in best_nodes]\n",
    "    cent_dict_baba_corr_15[method] = [cnt[0] for cnt in best_nodes[:15]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "scores_15 = {}\n",
    "mean_realisation = 50\n",
    "for method, nodes in cent_dict_baba_corr.items():\n",
    "    node_labels = []\n",
    "    nodes_scores = []\n",
    "    for node in nodes:\n",
    "        mean_spread = []\n",
    "        for _ in range(mean_realisation):\n",
    "            beta_param = {0: {0: 0.1, 1: 0.1}, 1: {0: 0.6, 1: 0.6}}\n",
    "            rec_param = {0: {0: 1.0, 1: 1.0}, 1: {0: 1.0, 1: 1.0}}\n",
    "            sis = SIRMultiplex(multi_baba_corr, beta=beta_param, mu=rec_param, seed_nodes=[node])\n",
    "            sis.run(epochs=10, visualize=False)\n",
    "            mean_spread.append(sis.get_num('i') + sis.get_num('r'))\n",
    "        node_labels.append(node)\n",
    "        nodes_scores.append(np.mean(mean_spread))\n",
    "    scores[method] = node_labels, nodes_scores\n",
    "    scores_15[method] = nodes_scores[:15]\n",
    "pd.DataFrame.from_dict(scores_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_mean(x, nnodes):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0))\n",
    "    return (cumsum[nnodes:] - cumsum[:-nnodes]) / nnodes\n",
    "\n",
    "idx_counter = 1\n",
    "colors = \"bgrcmrkygbb\"\n",
    "fig=plt.figure(figsize=(20, 20), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.subplots_adjust(top=1.5)\n",
    "for method, nd_lab_scores in scores.items():\n",
    "    sp = plt.subplot(840 + idx_counter)\n",
    "    sp.plot(running_mean(nd_lab_scores[1], 30), colors[idx_counter + 1])\n",
    "    sp.set_title(method)\n",
    "    idx_counter += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_mean(x, nnodes):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0))\n",
    "    return (cumsum[nnodes:] - cumsum[:-nnodes]) / nnodes\n",
    "\n",
    "idx_counter = 1\n",
    "corr_kendal = {}\n",
    "colors = \"bgrcmrkygbcmgrc\"\n",
    "fig=plt.figure(figsize=(20, 20), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.subplots_adjust(top=1.5)\n",
    "for method, nd_lab_scores in scores.items():\n",
    "    normalized_spread = (np.array(nd_lab_scores[1]) - np.mean(nd_lab_scores[1])) / np.std(nd_lab_scores[1])\n",
    "    normalized_cent = (cent_val_baba_corr[method] - np.mean(cent_val_baba_corr[method])) / np.std(cent_val_baba_corr[method])\n",
    "    sp = plt.subplot(840 + idx_counter)\n",
    "    sp.plot(normalized_spread, colors[idx_counter], label=\"spreading eff\")\n",
    "    sp.plot(running_mean(normalized_spread, 30), colors[idx_counter + 1], label=\"spreading mean\")\n",
    "    sp.plot(normalized_cent, colors[idx_counter + 2], label=\"centrality\")\n",
    "    sp.legend()\n",
    "    tau, p_value = stats.kendalltau(\n",
    "                    nd_lab_scores[1],\n",
    "                    cent_val_baba_corr[method]\n",
    "                )\n",
    "    corr_kendal[method] = [tau]\n",
    "    sp.set_title(method)\n",
    "    idx_counter += 1\n",
    "plt.show()\n",
    "print(\"Kendal Correlation\")\n",
    "pd.DataFrame.from_dict(corr_kendal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "print(\"Network generated and constructed!\")\n",
    "beta_param = {0: {0: 0.1, 1: 0.1}, 1: {0: 0.6, 1: 0.6}}\n",
    "rec_param = {0: {0: 1.0, 1: 1.0}, 1: {0: 1.0, 1: 1.0}}\n",
    "test_props = {'mean_num': 1500, \"epochs\": 35, \"beta\": beta_param, \"mu\": rec_param}\n",
    "print(\"Start process...\")\n",
    "spread_val, cent_scores, results_names = spread_eff_centr_test(multi_baba_corr, test_properties=test_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 20), dpi=80, facecolor='w', edgecolor='k')\n",
    "for method_idx in range(1, spread_val.shape[0]):\n",
    "    method_scores_spread = spread_val[method_idx]\n",
    "    method_scores_cent = cent_scores[method_idx]\n",
    "    method_scores_cent = method_scores_cent - np.min(method_scores_cent)\n",
    "    method_scores_cent = 0.65 * (method_scores_cent / np.max(method_scores_cent))\n",
    "    # Find data ranks\n",
    "    temp_sort = np.argsort(method_scores_cent)\n",
    "    data_centrality_rank = np.empty(len(method_scores_cent), int)\n",
    "    data_centrality_rank[temp_sort] = np.arange(len(method_scores_cent))\n",
    "    sp = plt.subplot(240 + method_idx)\n",
    "    for node_id in range(network_size):\n",
    "        color_rgb = colorsys.hsv_to_rgb(0.65 - method_scores_cent[node_id], 0.5, 1.0)\n",
    "        sp.scatter(data_centrality_rank[node_id], method_scores_spread[node_id],\n",
    "                   c=(color_rgb[0], color_rgb[1], color_rgb[2], 1))\n",
    "    sp.set_title(results_names[method_idx - 1])\n",
    "    sp.set_ylim([np.min(method_scores_spread), np.max(method_scores_spread)])\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
